{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal echoing\n",
    "\n",
    "Echoing signal `n` steps is an example of synchronized many-to-many task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequential_tasks import EchoData\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# By taking away these seeds, we see that even performance here is very stochastic.\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "# np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "echo_step = 3\n",
    "series_length = 20_000\n",
    "BPTT_T = 20\n",
    "\n",
    "# EchoData provides input and target data for training a network to\n",
    "# echo a `series_length`-long stream of data. `.x_batch` contains the input series,\n",
    "# it has shape `[batch_size, series_length]`; `.y_batch` contains the target data,\n",
    "# it has the same shape as `.x_batch`.\n",
    "#\n",
    "# Unlike other training data in this course, successive batches from a single `EchoData`\n",
    "# object draw from the same stream. For example, in 08-seq_classification, training data\n",
    "# has the following format:\n",
    "#\n",
    "#   [[S11 S12...S1N], [S21 S22...S2N], ..., [SM1 SM2...SMN]]\n",
    "#\n",
    "# where `SIJ` represents the `j`th sample drawn from the `i`th stream. \n",
    "#\n",
    "# However, `EchoData` output has the following format (slicing along the batch dimension):\n",
    "#\n",
    "#   [[S11 S21...S1N], [S1(N+1) S1(N+2)...S2(2N)], ..., [S1(MN) S1(MN+1)...SM(MNN)]]\n",
    "#\n",
    "# This means that successive batches of data drawn from the same `EchoData` object\n",
    "# are not independent.\n",
    "train_data = EchoData(\n",
    "    echo_step=echo_step,\n",
    "    batch_size=batch_size,\n",
    "    series_length=series_length,\n",
    "    truncated_length=BPTT_T\n",
    ")\n",
    "total_values_in_one_chunck = batch_size * BPTT_T\n",
    "train_size = len(train_data)\n",
    "\n",
    "test_data = EchoData(\n",
    "    echo_step=echo_step,\n",
    "    batch_size=batch_size,\n",
    "    series_length=series_length,\n",
    "    truncated_length=BPTT_T,\n",
    ")\n",
    "test_data.generate_new_series()\n",
    "test_data.prepare_batches()\n",
    "test_size = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1st input sequence)  x: 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 ... \n",
      "(1st target sequence) y: 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 ... \n",
      "(1st input sequence)  x: 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 ... \n",
      "(1st target sequence) y: 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 ... \n"
     ]
    }
   ],
   "source": [
    "# Let's print first 20 timesteps of the first sequences to see the echo data:\n",
    "print('(1st input sequence)  x:', *train_data.x_batch[0, :20], '... ')\n",
    "print('(1st target sequence) y:', *train_data.y_batch[0, :20], '... ')\n",
    "\n",
    "print('(1st input sequence)  x:', *test_data.x_batch[0, :20], '... ')\n",
    "print('(1st target sequence) y:', *test_data.y_batch[0, :20], '... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch:\n",
      "1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 ...\n",
      "1 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 ...\n",
      "0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 ...\n",
      "0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 ...\n",
      "1 1 0 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 ...\n",
      "x_batch size: (5, 20000)\n",
      "\n",
      "y_batch:\n",
      "0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 ...\n",
      "0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 ...\n",
      "0 0 0 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 ...\n",
      "0 0 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 ...\n",
      "0 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 0 1 1 0 ...\n",
      "y_batch size: (5, 20000)\n"
     ]
    }
   ],
   "source": [
    "# batch_size different sequences are created:\n",
    "print('x_batch:', *(str(d)[1:-1] + ' ...' for d in train_data.x_batch[:, :20]), sep='\\n')\n",
    "print('x_batch size:', train_data.x_batch.shape)\n",
    "print()\n",
    "print('y_batch:', *(str(d)[1:-1] + ' ...' for d in train_data.y_batch[:, :20]), sep='\\n')\n",
    "print('y_batch size:', train_data.y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_chunk:\n",
      "[1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0]\n",
      "[1 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "[0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0]\n",
      "[0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0]\n",
      "[1 1 0 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0]\n",
      "1st x_chunk size: (5, 20, 1)\n",
      "\n",
      "y_chunk:\n",
      "[0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1]\n",
      "[0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1]\n",
      "[0 0 0 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1]\n",
      "[0 0 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1]\n",
      "[0 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 0 1 1 0]\n",
      "1st y_chunk size: (5, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "# In order to use RNNs data is organized into temporal\n",
    "# chunks of size [batch_size, T, feature_dim]\n",
    "print('x_chunk:', *train_data.x_chunks[0].squeeze(), sep='\\n')\n",
    "print('1st x_chunk size:', train_data.x_chunks[0].shape)\n",
    "print()\n",
    "print('y_chunk:', *train_data.y_chunks[0].squeeze(), sep='\\n')\n",
    "print('1st y_chunk size:', train_data.y_chunks[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, rnn_hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = torch.nn.RNN( # This generates a series of encodings\n",
    "            input_size=input_size,\n",
    "            hidden_size=rnn_hidden_size,\n",
    "            num_layers=1, # Deep RNNs have a stack of hidden representations.\n",
    "            nonlinearity='relu', # Also, why isn't there a weighting on the losses,\n",
    "            # Such that the losses from later rounds are weighed more than\n",
    "            # earlier ones, because some sequences start without any context, and\n",
    "            # this just creates noise.\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.linear = torch.nn.Linear( # This is the decoder\n",
    "            in_features=rnn_hidden_size,\n",
    "            out_features=output_size\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # In order to model the fact that successive batches belong to the same stream of data,\n",
    "        # we share the hidden state across successive invocations.\n",
    "        rnn_out, hidden = self.rnn(x, hidden)  \n",
    "        if self.training:\n",
    "            rnn_out.retain_grad()\n",
    "        out = self.linear(rnn_out)\n",
    "        return out, hidden, rnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0 torch.Size([4, 1])\n",
      "rnn.weight_hh_l0 torch.Size([4, 4])\n",
      "rnn.bias_ih_l0 torch.Size([4])\n",
      "rnn.bias_hh_l0 torch.Size([4])\n",
      "linear.weight torch.Size([1, 4])\n",
      "linear.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "m = SimpleRNN(\n",
    "    input_size=1,\n",
    "    rnn_hidden_size=4,\n",
    "    output_size=1\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name, param in m.named_parameters():\n",
    "        print(name, param.shape)\n",
    "# Corresponds to ReLU(W_ih x_t + W_hh h_t-1 + b_ih + b_hh)\n",
    "# And there are two biases just for compatibility with LSTM/GRU\n",
    "\n",
    "# For the linear weights, the gradient computation is straightforward\n",
    "# There is no problem with optimization there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    # New epoch --> fresh hidden state\n",
    "    hidden = None   \n",
    "    correct = 0\n",
    "    for batch_idx in range(train_size):\n",
    "        data, target = train_data[batch_idx]\n",
    "        data, target = torch.from_numpy(data).float().to(device), torch.from_numpy(target).float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        if hidden is not None: hidden.detach_()\n",
    "        logits, hidden, _ = model(data, hidden)\n",
    "\n",
    "        # RNN has a bijection between \n",
    "        # print(data.shape, target.shape)\n",
    "\n",
    "        loss = criterion(logits, target) # It doesn't do anything really special\n",
    "        # It just has a 1-1 mapping between data and target, all at once.\n",
    "        # And then it later on does a topological sort, rooted at loss.\n",
    "        loss.backward() # Calculates all gradients involved (anything that has autograd=True)\n",
    "        # And adds the grad dL/dw_i\n",
    "        optimizer.step() # This just steps all of those things, but carefully (i.e. following\n",
    "        # a stepping algorithm, like AdamW)\n",
    "\n",
    "        \n",
    "        pred = (torch.sigmoid(logits) > 0.5)\n",
    "        correct += (pred == target.byte()).int().sum().item()/total_values_in_one_chunck\n",
    "        \n",
    "    return correct, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()   \n",
    "    correct = 0\n",
    "    # New epoch --> fresh hidden state\n",
    "    hidden = None\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in range(test_size):\n",
    "            data, target = test_data[batch_idx]\n",
    "            data, target = torch.from_numpy(data).float().to(device), torch.from_numpy(target).float().to(device)\n",
    "            logits, hidden, _ = model(data, hidden)\n",
    "            \n",
    "            pred = (torch.sigmoid(logits) > 0.5)\n",
    "            correct += (pred == target.byte()).int().sum().item()/total_values_in_one_chunck\n",
    "\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 1 #since we have a scalar series\n",
    "h_units = 4\n",
    "\n",
    "model = SimpleRNN(\n",
    "    input_size=1,\n",
    "    rnn_hidden_size=h_units,\n",
    "    output_size=feature_dim\n",
    ").to(device)\n",
    "        \n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1/5, loss: 0.594, accuracy 60.0%\n",
      "Train Epoch: 2/5, loss: 0.588, accuracy 65.4%\n",
      "Train Epoch: 3/5, loss: 0.481, accuracy 69.0%\n",
      "Train Epoch: 4/5, loss: 0.568, accuracy 69.2%\n",
      "Train Epoch: 5/5, loss: 0.551, accuracy 69.1%\n",
      "Test accuracy: 68.8%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    correct, loss = train()\n",
    "    train_accuracy = float(correct)*100/ train_size\n",
    "    print(f'Train Epoch: {epoch}/{n_epochs}, loss: {loss:.3f}, accuracy {train_accuracy:.1f}%')\n",
    "\n",
    "#test    \n",
    "correct = test()\n",
    "test_accuracy = float(correct) * 100 / test_size\n",
    "print(f'Test accuracy: {test_accuracy:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "         0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "         1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "         1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "         1, 0, 0, 1]], dtype=torch.uint8)\n",
      "tensor([[1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "         1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "         1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "         1, 0, 1, 0]], dtype=torch.uint8)\n",
      "[False False False False  True False  True False  True  True  True  True\n",
      " False False  True  True  True  True  True False  True  True  True  True\n",
      "  True False  True  True False  True  True  True  True False  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True  True\n",
      " False False False False False  True False  True  True  True  True  True\n",
      "  True  True  True False False False  True  True  True  True  True  True\n",
      "  True False False  True  True  True  True  True  True  True  True False\n",
      "  True False  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True False]\n"
     ]
    }
   ],
   "source": [
    "# Let's try some echoing\n",
    "my_input = torch.empty(1, 100, 1).random_(2)\n",
    "hidden = None\n",
    "my_out, _, _ = model(my_input.to(device), hidden)\n",
    "my_pred = torch.where(my_out > .5, \n",
    "                      torch.ones_like(my_out), \n",
    "                      torch.zeros_like(my_out)).cpu()\n",
    "print(my_input.view(1, -1).byte(), my_pred.view(1, -1).byte(), sep='\\n')\n",
    "\n",
    "# Calculate the expected output for our random input\n",
    "expected = np.roll(my_input, echo_step)\n",
    "expected[:, :echo_step] = 0\n",
    "correct = expected == my_pred.numpy()\n",
    "print(np.ndarray.flatten(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 1 #since we have a scalar series\n",
    "h_units = 4\n",
    "\n",
    "model = SimpleRNN(\n",
    "    input_size=1,\n",
    "    rnn_hidden_size=h_units,\n",
    "    output_size=feature_dim\n",
    ").to(device)\n",
    "        \n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/32/bzhrljpn11q6c0sjbvcy_mnc0000gq/T/ipykernel_16188/4281385684.py:55: RuntimeWarning: divide by zero encountered in log\n",
      "  log_dEt_dhk_norm_avg = [np.log(x) for x in list_dEt_dhk_norm_avg]\n",
      "/var/folders/32/bzhrljpn11q6c0sjbvcy_mnc0000gq/T/ipykernel_16188/4281385684.py:55: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  log_dEt_dhk_norm_avg = [np.log(x) for x in list_dEt_dhk_norm_avg]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(876.5699999999989, tensor(0.1236))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "model.train()\n",
    "\n",
    "# New epoch --> fresh hidden state\n",
    "hidden = None   \n",
    "correct = 0\n",
    "for batch_idx in range(train_size):\n",
    "    data, target = train_data[batch_idx]\n",
    "    data, target = torch.from_numpy(data).float().to(device), torch.from_numpy(target).float().to(device)\n",
    "    optimizer.zero_grad()\n",
    "    if hidden is not None: hidden.detach_()\n",
    "\n",
    "    # Prediction, and tracking hidden states\n",
    "    # time_steps = data.shape[1]\n",
    "    logits, hidden, hidden_states = model(data, hidden)\n",
    "\n",
    "    # print(hidden_states.shape, hidden_states)\n",
    "    # print(logits.shape, logits)\n",
    "    # print(hidden.shape, hidden)\n",
    "\n",
    "    # RNN has a bijection between \n",
    "    # print(data.shape, target.shape)\n",
    "\n",
    "    # Do this thing below, and then normalize by that, like divide every\n",
    "    # gradient step by the L2 norm.\n",
    "    \n",
    "    seq_len = target.shape[1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    batch_of_interest = 100\n",
    "\n",
    "    loss_arr = []\n",
    "    prev_loss_arr = [torch.zeros((5, 20, 4))]\n",
    "    for i in range(seq_len):\n",
    "        if i < seq_len - 1:\n",
    "            continue\n",
    "        # if hidden_states.grad is not None:\n",
    "        #     hidden_states.grad.zero_()\n",
    "\n",
    "        loss_arr.append(criterion(logits[:, i:i+1, :], target[:,i:i+1,:])) # This isn't the 5 step training loop, and will yield problems if I do backward, step all inside the loop\n",
    "        loss_arr[-1].backward(retain_graph=True) # need to use retain_graph because if we don't it won't remember the feedforward step we did\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if batch_idx == batch_of_interest:\n",
    "                dEt_dhk = hidden_states.grad - prev_loss_arr[-1] # Need to do this, because hidden_states holds the sum_{i<=t} dEi_dhk\n",
    "                prev_loss_arr.append(hidden_states.grad.clone())\n",
    "\n",
    "                dEt_dhk_norm = torch.norm(dEt_dhk, p=2, dim=-1)\n",
    "                dEt_dhk_norm_avg = torch.mean(dEt_dhk_norm, dim=0)\n",
    "\n",
    "                list_dEt_dhk_norm_avg = list(dEt_dhk_norm_avg.detach().cpu())\n",
    "                log_dEt_dhk_norm_avg = [np.log(x) for x in list_dEt_dhk_norm_avg]\n",
    "\n",
    "                cmap = cm.viridis\n",
    "                if i == 0:\n",
    "                    plt.figure(figsize=(20, 15))\n",
    "                plt.scatter(range((dEt_dhk_norm_avg.detach().cpu().shape[0])), \n",
    "                         log_dEt_dhk_norm_avg, \n",
    "                         color=cmap(i/(seq_len-1)), \n",
    "                         label=f\"{i} : {loss_arr[-1].detach().cpu().item():.3f}\")\n",
    "    if batch_idx == batch_of_interest:\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # training time i=0 first, then stepping, then training time i=1 next, then stepping\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss = sum(loss_arr)/len(loss_arr)\n",
    "    optimizer.step()\n",
    "    \n",
    "    pred = (torch.sigmoid(logits) > 0.5)\n",
    "    correct += (pred == target.byte()).int().sum().item()/total_values_in_one_chunck\n",
    "    \n",
    "correct, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
